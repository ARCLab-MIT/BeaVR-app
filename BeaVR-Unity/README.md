# BeaVR Unity Project

**Unity 6.2** | **OpenXR** | **XR Hands**

---

## ğŸ“ Project Structure

```
Assets/
â”œâ”€â”€ Scripts/
â”‚   â”œâ”€â”€ Gesture Detection/
â”‚   â”‚   â””â”€â”€ GestureDetectorXR.cs       # Hand tracking & pinch detection
â”‚   â”œâ”€â”€ Network/
â”‚   â”‚   â””â”€â”€ NetMQController.cs         # NetMQ messaging
â”‚   â”œâ”€â”€ NetworkManager.cs              # Network config
â”‚   â”œâ”€â”€ UI/                            # IP input, canvas switching
â”‚   â”œâ”€â”€ Camera Stream Scripts/
â”‚   â”‚   â””â”€â”€ CameraOneStreamer.cs       # Receive camera feed
â”‚   â””â”€â”€ GraphStream.cs                 # Receive graph data
â”‚
â””â”€â”€ Resources/Configurations/
    â””â”€â”€ Network.json                   # IP addresses & ports
```

---

## ğŸ”„ Data Flow

```
XR Hands Subsystem
       â†“
GestureDetectorXR (26 joints/hand)
       â†“
NetMQController.SendMessage()
       â†“
   [Network]  â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â†“                    â”‚
   Server              CameraOneStreamer
                       GraphStream
```

**Message Format**: `"x,y,z,x,y,z,..."` (78 floats per hand)

---

## Core Components

| Component | Purpose |
|-----------|---------|
| `GestureDetectorXR.cs` | XR Hands tracking â†’ NetMQ |
| `NetMQController.cs` | ZeroMQ pub/sub messaging |
| `NetworkManager.cs` | Load `Network.json` config |
| `CameraOneStreamer.cs` | Receive & display camera |
| `GraphStream.cs` | Receive & display graphs |

### Hand Joint Order (XR Hands)
```
0:Wrist  1:Palm
2-6:   Thumb (Metacarpalâ†’Tip)
7-11:  Index
12-16: Middle
17-21: Ring
22-26: Little
```

---

## âš™ï¸ Unity Setup

### Required Packages
- XR Plugin Management
- XR Hands (v1.6.1)
- XR Interaction Toolkit
- NetMQ 4.0.2.1 (NuGet)

### Project Settings
```
XR Plug-in Management â†’ OpenXR
  âœ“ OpenXR provider
  âœ“ Meta XR Hand Tracking Aim
```

### Scene Requirements
```
XR Origin (XR Rig)
  â”œâ”€â”€ Camera Offset
  â”‚   â””â”€â”€ Main Camera
  â””â”€â”€ [Controllers/Hands]

EventSystem
  â””â”€â”€ XR UI Input Module

Canvas (World Space)
  â””â”€â”€ Tracked Device Graphic Raycaster
```

---

## Building for Quest

| Setting | Value |
|---------|-------|
| **Platform** | Android |
| **Scripting Backend** | IL2CPP |
| **Target API Level** | 32+ |
| **Texture Compression** | ASTC |
| **XR Provider** | OpenXR (Android tab) |

**Build**: File â†’ Build Settings â†’ Build and Run

---

## Troubleshooting

**Common Issues:**
- **NuGet packages not loading**: Reinstall NuGet packages (NetMQ, AsyncIO, NaCl.Net)
- **Hand tracking not working**: Enable OpenXR Hand Tracking Subsystem in Project Settings
- **Build settings**: Platform (Android) and Target API Level (32+) are already configured

---

## ğŸ“¦ Dependencies

**NuGet** (in `Assets/Packages/`):
- NetMQ 4.0.2.1
- AsyncIO 0.1.69
- NaCl.Net 0.1.13

**Unity**:
- XR Hands (1.6.1)
- XR Interaction Toolkit
- TextMesh Pro

---

## OVR vs OpenXR

This project uses **OpenXR with Meta XR Interaction building blocks** instead of the legacy Oculus Integration SDK.

**Key Differences:**
- **Hand Tracking**: XR Hands provides 26 joints per hand vs OVR's bone structure
- **Joint Order**: Different ordering - ensure receiver code matches XR Hands format (see above)
- **Scene Setup**: Uses Meta XR Interaction building blocks for camera rig and UI interaction

---

## License

MIT License